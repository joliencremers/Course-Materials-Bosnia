---
title: "Practical M"
author: "Jolien Cremers"
date: "Statistical Programming in R"
output: html_document
---

---

#### Exercise Math Achievement 

--- 

Using the dataset `MathAchieve`in the `MEMSS` package carry out an analysis that
treats `School` as a random effect. Answer the following questions:

    -Which variables should be treated as fixed effects?
    -Are differences between schools greater than can be explained by within-school variation?
    -Is the relation between SES and MathAch different for different schools? Compare the models using deviance difference tests.
    -Discuss how the decision whether to treat `School` as a fixed or a random effect might depend on the purpose of the study. 
---

1. **Which variables should be treated as fixed effects?**

Minority, SES, Sex and MEANSES can be treated as fixed effects (SES can also be
treated as random).

---

2. **Are differences between schools greater than can be explained by within-school variation?**

To obtain deviances we use full maximum likelihood estimation (REML=F). First
fit an empty model, to see whether there are any differences between schools:

```{r, message = F, warning = F}
#Load the required packages into the environment.
library(MEMSS)
library(lme4)

#Fit an intercept-only model.
fit1 <- lmer(MathAch ~ 1 + (1 | School), data = MathAchieve, REML=F)

#Look at the summary of the fit object.
summary(fit1)
```

The between school (2nd level) variance is 8.55, if we fit a new model using
within school effects (note that we need to include MEANSES, a between school
variable, to make sure that SES is a 'pure' within school and MEANSES a 'pure'
between school effect).


```{r}
#Fit a model with the within school predictors and MEANSES.
fit2 <- lmer(MathAch ~ Minority + SES + Sex + MEANSES +
                      (1 | School),
             data = MathAchieve, REML=F)

#Look at the summary of the fit object.
summary(fit2)
```

```{r}
#Compare the fits of the intercept-only model and model with within school predictors.
anova(fit1, fit2)
```

We see that part of the between school variance is explained (8.55-2.40=6.15).
The deviance difference between this and the previous model is equal to
(47115.8-46333.3=782.5, df=4, p<0.001).

---

3. **Is the relation between SES and MathAch different for different schools? Compare the models using deviance difference tests.**

To check whether the relation between SES and MathAch is different for different
schools we add a random slope for SES.

```{r}
#Fit a model with a random slope for MEANSES.
fit3 <- lmer(MathAch ~ Minority + SES + Sex + MEANSES +
                      (1 + SES | School),
             data = MathAchieve, REML=F)
#Look at the summary of the fit object.
summary(fit3)
```

```{r}
#Compare the fits of the previous three models.
anova(fit1, fit2, fit3)
```

We see that there is some random slope variance (0.32), The deviance difference
between this and the previous model is equal to (46333-46321=12, df=2, p=0.002).
The best model for this data, based on the deviances, is thus model 3 (with
random slope for SES).

---

4. **Discuss how the decision whether to treat `School` as a fixed or a random effect might depend on the purpose of the study.**

If the purpose of the study is to generalize to all schools in a specific
region/country, and a random sample of schools was taken, the school variable
can be considered random. If the purpose is to compare a specific set of
schools, not randomly sampled, school is fixed.

---

#### Exercise Nurses

---

The file nurses.sav holds data from nurses working in wards nested within
hospitals (Hox, J.J. (2002). *Multilevel analysis: Techniques and applications.*
Hove: Routledge). It is from a hypothetical study on stress in hospitals where
wards were randomly assigned to and experimental or control condition. It
contains the variables `age`(years),  `experience`(years), `gender` (0=m, 1=f),
`wardtype` (0=general care, 1=special care), `expcon` (0=control,
1=experimental), `hospsize` (0=small, 1=medium, 2=large), `stress` (likert scale
1-7) and the id variables `hospital`, `ward` and `nurse`.

Load this file into R using the function `read_spss()` from the `haven` package,
grand mean center (centering based on the mean over all hospitals) the variables
`age` and `experience` and answer the following questions:

    - Are differences between wards greater than can be explained by ward and nurse varying variables?
    - Are differences between hospitals greater than can be explained by hospital, ward and nurse varying 
      variables?
    - Is the relation between experimental condition and mean ward stress-score the same in all hospitals?
    - If this relation is different, can the size of the hospital explain (a part of) these different 
      relations?

---

1. **Are differences between wards greater than can be explained by ward and nurse varying variables?**
2. **Are differences between hospitals greater than can be explained by hospital, ward and nurse varying variables?**

```{r, message = F}
#Load the required packages into the environment. Note that we already loaded the lme4 package in the previous exercise so actually we do not need to load it again.
require(haven)
require(lme4)

#Load the data into R
Nurses <- read_spss("nurses.sav") 
#Don't forget to set working directory correctly or to specify a different file location.
```

First, fit an empty (intercept-only) model

```{r}
fit1 <- lmer(stress ~ 1 + (1 | hospital) + (1 | hospital:ward),
             data = Nurses, REML=F)
summary(fit1)
```

We see that most of the variation lies at the ward level (0.49). Next we fit a
model with fixed effects (remember to grand mean center `age` and `experience`).
Grand mean centering is done for interpretation purposes. There are other ways
of centering variables (group mean centering) that lead to different
interpretations of the effects.


```{r}
#Grand mean center the age and experience variables
Nurses$age <- Nurses$age - mean(Nurses$age)
Nurses$experience <- Nurses$experience - mean(Nurses$experience)

#Fit the fixed-effects model
fit2 <- lmer(stress ~ 1 + age + gender + experience + wardtype + expcon + hospsize + 
                      (1 | hospital) + (1 | hospital:ward),
             data = Nurses, REML=F)

summary(fit2)
```

We see that the variance at all levels decreases, so some of it is explained by
hospital, nurse and ward varying variables but not all.

---

3. **Is the relation between experimental condition and mean ward stress-score the same in all hospitals?**

To test whether the relation between experimental condition and mean ward
stress-score is the same in all hospitals we add a random effect for
experimental condition.

```{r}
fit3 <- lmer(stress ~ 1 + age + gender + experience + wardtype + expcon + hospsize +
                      (1 + expcon | hospital) + (1 | hospital:ward),
             data = Nurses, REML=F)

summary(fit3)
```

Indeed, the variance of the random slope for experimental condition is 0.66,
leading us to assume that the relation between experimental condition and mean
ward stress-score is different between hospitals (formally however, we would
like to test whether this variance is really diferent from 0).

---

4. **If this relation is different, can the size of the hospital explain (a part of) these different relations?**

To see whether part of this variation in slopes can be explained by hospital
size we add a so called "cross-level interaction"


```{r}
fit4 <- lmer(stress ~ 1 + age + gender + experience + wardtype + expcon*hospsize + 
                      (1 + expcon | hospital) + (1 | hospital:ward),
             data = Nurses, REML=F)

summary(fit4)
```

```{r}
anova(fit1, fit2, fit3, fit4)
```

We see that the slope variance of experimental condition decreases from 0.66 to
0.18. The coefficient for the cross-level interaction is equal to 0.998, t=6.22
(so probably significant if we formally test it). If we do a deviance difference
test on the previous two models (1574.2-1550.8=23.4, df=1, p<0.01) we see that
the model with cross-level interaction fits better.

--- 

End of `Practical`. 